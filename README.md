## Background
Seismic data is collected using reflection seismology, or seismic reflection. The method requires a controlled seismic source of energy, such as compressed air or a seismic vibrator, and sensors record the reflection from rock interfaces within the subsurface. The recorded data is then processed to create a 3D view of earthâ€™s interior. Reflection seismology is similar to X-ray, sonar and echolocation.

A seismic image is produced from imaging the reflection coming from rock boundaries. The seismic image shows the boundaries between different rock types. In theory, the strength of reflection is directly proportional to the difference in the physical properties on either sides of the interface. While seismic images show rock boundaries, they don't say much about the rock themselves; some rocks are easy to identify while some are difficult.

There are several areas of the world where there are vast quantities of salt in the subsurface. One of the challenges of seismic imaging is to identify the part of subsurface which is salt. Salt has characteristics that makes it both simple and hard to identify. Salt density is usually 2.14 g/cc which is lower than most surrounding rocks. The seismic velocity of salt is 4.5 km/sec, which is usually faster than its surrounding rocks. This difference creates a sharp reflection at the salt-sediment interface. Usually salt is an amorphous rock without much internal structure. This means that there is typically not much reflectivity inside the salt, unless there are sediments trapped inside it. The unusually high seismic velocity of salt can create problems with seismic imaging.

## Data
The data is a set of images chosen at various locations chosen at random in the subsurface. The images are 101 x 101 pixels and each pixel is classified as either salt or sediment. In addition to the seismic images, the depth of the imaged location is provided for each image. The goal of the competition is to segment regions that contain salt. The data can be found at the link: [DATA](https://www.kaggle.com/competitions/tgs-salt-identification-challenge/data)


## Approach
The input image size was (101,101). So I have resized the image to (128,128). The image augmentation includes Flipping the images and corresponding mask , random crop and resize , 10 degree rotation and rolling the images. The training data was spliited into 5 folds and in each fold a neural network was used. The architecture of neural network was Resnet with unet. The resnet block was inspired from this paper : [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf).

For each fold the neural net was trained with 80 epochs and 64 batch size with binary cross entropy loss and after that 80 epochs and 64 batch size with Lovasz Loss.  For total 160 epochs, model was observed using model checkpoint in keras and only saved the weights for which the validaition IoU increased. The test data augmentation include flipping the images. 
